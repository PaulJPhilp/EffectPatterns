[
  {
    "path": "rules/cursor/add-caching-by-wrapping-a-layer.mdc",
    "contents": "description: Use a wrapping Layer to add cross-cutting concerns like caching to a service without altering its original implementation.\nglobs: \"**/*.ts\"\nalwaysApply: true\n\n# Add Caching by Wrapping a Layer\n**Rule:** Use a wrapping Layer to add cross-cutting concerns like caching to a service without altering its original implementation.\n\n### Example\nWe have a `WeatherService` that makes slow API calls. We create a `WeatherService.cached` wrapper layer that adds an in-memory cache using a `Ref` and a `Map`.\n\n```typescript\nimport { Effect, Layer, Ref } from \"effect\";\n\n// 1. Define the service interface\nclass WeatherService extends Effect.Service<WeatherService>()(\n  \"WeatherService\",\n  {\n    sync: () => ({\n      getForecast: (city: string) => Effect.succeed(`Sunny in ${city}`),\n    }),\n  }\n) {}\n\n// 2. The \"Live\" implementation that is slow\nconst WeatherServiceLive = Layer.succeed(\n  WeatherService,\n  WeatherService.of({\n    _tag: \"WeatherService\",\n    getForecast: (city) =>\n      Effect.succeed(`Sunny in ${city}`).pipe(\n        Effect.delay(\"2 seconds\"),\n        Effect.tap(() => Effect.log(`Fetched live forecast for ${city}`))\n      ),\n  })\n);\n\n// 3. The Caching Wrapper Layer\nconst WeatherServiceCached = Layer.effect(\n  WeatherService,\n  Effect.gen(function* () {\n    // It REQUIRES the original WeatherService\n    const underlyingService = yield* WeatherService;\n    const cache = yield* Ref.make(new Map<string, string>());\n\n    return WeatherService.of({\n      _tag: \"WeatherService\",\n      getForecast: (city) =>\n        Ref.get(cache).pipe(\n          Effect.flatMap((map) =>\n            map.has(city)\n              ? Effect.log(`Cache HIT for ${city}`).pipe(\n                  Effect.as(map.get(city)!)\n                )\n              : Effect.log(`Cache MISS for ${city}`).pipe(\n                  Effect.flatMap(() => underlyingService.getForecast(city)),\n                  Effect.tap((forecast) =>\n                    Ref.update(cache, (map) => map.set(city, forecast))\n                  )\n                )\n          )\n        ),\n    });\n  })\n);\n\n// 4. Compose the final layer. The wrapper is provided with the live implementation.\nconst AppLayer = Layer.provide(WeatherServiceCached, WeatherServiceLive);\n\n// 5. The application logic\nconst program = Effect.gen(function* () {\n  const weather = yield* WeatherService;\n  yield* weather.getForecast(\"London\"); // First call is slow (MISS)\n  yield* weather.getForecast(\"London\"); // Second call is instant (HIT)\n});\n\nEffect.runPromise(Effect.provide(program, AppLayer));\n\n```\n\n---"
  },
  {
    "path": "rules/cursor/build-a-basic-http-server.mdc",
    "contents": "description: Use a managed Runtime created from a Layer to handle requests in a Node.js HTTP server.\nglobs: \"**/*.ts\"\nalwaysApply: true\n\n# Build a Basic HTTP Server\n**Rule:** Use a managed Runtime created from a Layer to handle requests in a Node.js HTTP server.\n\n### Example\nThis example creates a simple server with a `Greeter` service. The server starts, creates a runtime containing the `Greeter`, and then uses that runtime to handle requests.\n\n```typescript\nimport { HttpServer, HttpServerResponse } from \"@effect/platform\"\nimport { NodeHttpServer } from \"@effect/platform-node\"\nimport { Duration, Effect, Fiber, Layer } from \"effect\"\nimport { createServer } from \"node:http\"\n\n// Create a server layer using Node's built-in HTTP server\nconst ServerLive = NodeHttpServer.layer(() => createServer(), { port: 3001 })\n\n// Define your HTTP app (here responding \"Hello World\" to every request)\nconst app = Effect.gen(function* () {\n  yield* Effect.logInfo(\"Received HTTP request\")\n  return yield* HttpServerResponse.text(\"Hello World\")\n})\n\nconst serverLayer = HttpServer.serve(app).pipe(Layer.provide(ServerLive));\n\nconst program = Effect.gen(function* () {\n  yield* Effect.logInfo(\"Server starting on http://localhost:3001\")\n  const fiber = yield* Layer.launch(serverLayer).pipe(Effect.fork)\n  yield* Effect.sleep(Duration.seconds(2))\n  yield* Fiber.interrupt(fiber)\n  yield* Effect.logInfo(\"Server shutdown complete\")\n})\n\nEffect.runPromise(program as unknown as Effect.Effect<void, unknown, never>);\n```\n\n---"
  },
  {
    "path": "rules/cursor/create-a-managed-runtime-for-scoped-resources.mdc",
    "contents": "description: Create a managed runtime for scoped resources.\nglobs: \"**/*.ts\"\nalwaysApply: true\n\n# Create a Managed Runtime for Scoped Resources\n**Rule:** Create a managed runtime for scoped resources.\n\n### Example\n```typescript\nimport { Effect, Layer } from \"effect\";\n\nclass DatabasePool extends Effect.Service<DatabasePool>()(\n  \"DbPool\",\n  {\n    effect: Effect.gen(function* () {\n      yield* Effect.log(\"Acquiring pool\");\n      return {\n        query: () => Effect.succeed(\"result\")\n      };\n    })\n  }\n) {}\n\n// Create a program that uses the DatabasePool service\nconst program = Effect.gen(function* () {\n  const db = yield* DatabasePool;\n  yield* Effect.log(\"Using DB\");\n  yield* db.query();\n});\n\n// Run the program with the service implementation\nEffect.runPromise(\n  program.pipe(\n    Effect.provide(DatabasePool.Default),\n    Effect.scoped\n  )\n);\n```\n\n**Explanation:**  \n`Layer.launch` ensures that resources are acquired and released safely, even\nin the event of errors or interruptions."
  },
  {
    "path": "rules/cursor/create-a-reusable-runtime-from-layers.mdc",
    "contents": "description: Create a reusable runtime from layers.\nglobs: \"**/*.ts\"\nalwaysApply: true\n\n# Create a Reusable Runtime from Layers\n**Rule:** Create a reusable runtime from layers.\n\n### Example\n```typescript\nimport { Effect, Layer, Runtime } from \"effect\";\n\nclass GreeterService extends Effect.Service<GreeterService>()(\n  \"Greeter\",\n  {\n    sync: () => ({\n      greet: (name: string) => Effect.sync(() => `Hello ${name}`)\n    })\n  }\n) {}\n\nconst runtime = Effect.runSync(\n  Layer.toRuntime(GreeterService.Default).pipe(\n    Effect.scoped\n  )\n);\n\n// In a server, you would reuse `run` for every request.\nRuntime.runPromise(runtime)(Effect.log(\"Hello\"));\n```\n\n**Explanation:**  \nBy compiling your layers into a Runtime once, you avoid rebuilding the\ndependency graph for every effect execution."
  },
  {
    "path": "rules/cursor/decouple-fibers-with-queues-and-pubsub.mdc",
    "contents": "description: Use Queue for point-to-point work distribution and PubSub for broadcast messaging between fibers.\nglobs: \"**/*.ts\"\nalwaysApply: true\n\n# Decouple Fibers with Queues and PubSub\n**Rule:** Use Queue for point-to-point work distribution and PubSub for broadcast messaging between fibers.\n\n### Example\nA producer fiber adds jobs to a `Queue`, and a worker fiber takes jobs off the queue to process them.\n\n```typescript\nimport { Effect, Queue, Fiber } from \"effect\";\n\nconst program = Effect.gen(function* () {\n  yield* Effect.logInfo(\"Starting queue demo...\");\n\n  // Create a bounded queue that can hold a maximum of 10 items.\n  // This prevents memory issues by applying backpressure when the queue is full.\n  // If a producer tries to add to a full queue, it will suspend until space is available.\n  const queue = yield* Queue.bounded<string>(10);\n  yield* Effect.logInfo(\"Created bounded queue\");\n\n  // Producer Fiber: Add a job to the queue every second.\n  // This fiber runs independently and continuously produces work items.\n  // The producer-consumer pattern decouples work generation from work processing.\n  const producer = yield* Effect.gen(function* () {\n    let i = 0;\n    while (true) {\n      const job = `job-${i++}`;\n      yield* Effect.logInfo(`Producing ${job}...`);\n\n      // Queue.offer adds an item to the queue. If the queue is full,\n      // this operation will suspend the fiber until space becomes available.\n      // This provides natural backpressure control.\n      yield* Queue.offer(queue, job);\n\n      // Sleep for 500ms between job creation. This controls the production rate.\n      // Producer is faster than consumer (500ms vs 1000ms) to demonstrate queue buffering.\n      yield* Effect.sleep(\"500 millis\");\n    }\n  }).pipe(Effect.fork); // Fork creates a new fiber that runs concurrently\n\n  yield* Effect.logInfo(\"Started producer fiber\");\n\n  // Worker Fiber: Take a job from the queue and process it.\n  // This fiber runs independently and processes work items as they become available.\n  // Multiple workers could be created to scale processing capacity.\n  const worker = yield* Effect.gen(function* () {\n    while (true) {\n      // Queue.take removes and returns an item from the queue.\n      // If the queue is empty, this operation will suspend the fiber\n      // until an item becomes available. This prevents busy-waiting.\n      const job = yield* Queue.take(queue);\n      yield* Effect.logInfo(`Processing ${job}...`);\n\n      // Simulate work by sleeping for 1 second.\n      // This makes the worker slower than the producer, causing queue buildup.\n      yield* Effect.sleep(\"1 second\");\n      yield* Effect.logInfo(`Completed ${job}`);\n    }\n  }).pipe(Effect.fork); // Fork creates another independent fiber\n\n  yield* Effect.logInfo(\"Started worker fiber\");\n\n  // Let them run for a while...\n  // The main fiber sleeps while the producer and worker fibers run concurrently.\n  // During this time, you'll see the queue acting as a buffer between\n  // the fast producer and slow worker.\n  yield* Effect.logInfo(\"Running for 10 seconds...\");\n  yield* Effect.sleep(\"10 seconds\");\n  yield* Effect.logInfo(\"Done!\");\n\n  // Interrupt both fibers to clean up resources.\n  // Fiber.interrupt sends an interruption signal to the fiber,\n  // allowing it to perform cleanup operations before terminating.\n  // This is safer than forcefully killing fibers.\n  yield* Fiber.interrupt(producer);\n  yield* Fiber.interrupt(worker);\n\n  // Note: In a real application, you might want to:\n  // 1. Drain the queue before interrupting workers\n  // 2. Use Fiber.join to wait for graceful shutdown\n  // 3. Handle interruption signals in the fiber loops\n});\n\n// Run the program\n// This demonstrates the producer-consumer pattern with Effect fibers:\n// - Fibers are lightweight threads that can be created in large numbers\n// - Queues provide safe communication between fibers\n// - Backpressure prevents resource exhaustion\n// - Interruption allows for graceful shutdown\nEffect.runPromise(program);\n\n```\n\n\nA publisher sends an event, and multiple subscribers react to it independently.\n\n```typescript\nimport { Effect, PubSub } from \"effect\";\n\nconst program = Effect.gen(function* () {\n  const pubsub = yield* PubSub.bounded<string>(10);\n\n  // Subscriber 1: The \"Audit\" service\n  const auditSub = PubSub.subscribe(pubsub).pipe(\n    Effect.flatMap((subscription) =>\n      Effect.gen(function* () {\n        while (true) {\n          const event = yield* Queue.take(subscription);\n          yield* Effect.log(`AUDIT: Received event: ${event}`);\n        }\n      }),\n    ),\n    Effect.fork,\n  );\n\n  // Subscriber 2: The \"Notifier\" service\n  const notifierSub = PubSub.subscribe(pubsub).pipe(\n    Effect.flatMap((subscription) =>\n      Effect.gen(function* () {\n        while (true) {\n          const event = yield* Queue.take(subscription);\n          yield* Effect.log(`NOTIFIER: Sending notification for: ${event}`);\n        }\n      }),\n    ),\n    Effect.fork,\n  );\n\n  // Give subscribers time to start\n  yield* Effect.sleep(\"1 second\");\n\n  // Publisher: Publish an event that both subscribers will receive.\n  yield* PubSub.publish(pubsub, \"user_logged_in\");\n});\n```\n\n---"
  },
  {
    "path": "rules/cursor/execute-long-running-apps-with-effect-runfork.mdc",
    "contents": "description: Use Effect.runFork to launch a long-running application as a manageable, detached fiber.\nglobs: \"**/*.ts\"\nalwaysApply: true\n\n# Execute Long-Running Apps with Effect.runFork\n**Rule:** Use Effect.runFork to launch a long-running application as a manageable, detached fiber.\n\n### Example\nThis example starts a simple \"server\" that runs forever. We use `runFork` to launch it and then use the returned `Fiber` to shut it down gracefully after 5 seconds.\n\n```typescript\nimport { Effect, Fiber } from \"effect\";\n\n// A server that listens for requests forever\nconst server = Effect.log(\"Server received a request.\").pipe(\n  Effect.delay(\"1 second\"),\n  Effect.forever,\n);\n\nconsole.log(\"Starting server...\");\n\n// Launch the server as a detached, top-level fiber\nconst appFiber = Effect.runFork(server);\n\n// In a real app, you would listen for OS signals.\n// Here, we simulate a shutdown signal after 5 seconds.\nsetTimeout(() => {\n  console.log(\"Shutdown signal received. Interrupting server fiber...\");\n  // This ensures all cleanup logic within the server effect would run.\n  Effect.runPromise(Fiber.interrupt(appFiber));\n}, 5000);\n```\n\n---"
  },
  {
    "path": "rules/cursor/handle-unexpected-errors-by-inspecting-the-cause.mdc",
    "contents": "description: Handle unexpected errors by inspecting the cause.\nglobs: \"**/*.ts\"\nalwaysApply: true\n\n# Handle Unexpected Errors by Inspecting the Cause\n**Rule:** Handle unexpected errors by inspecting the cause.\n\n### Example\n```typescript\nimport { Cause, Effect, Data, Schedule, Duration } from \"effect\";\n\n// Define domain types\ninterface DatabaseConfig {\n  readonly url: string;\n}\n\ninterface DatabaseConnection {\n  readonly success: true;\n}\n\ninterface UserData {\n  readonly id: string;\n  readonly name: string;\n}\n\n// Define error types\nclass DatabaseError extends Data.TaggedError(\"DatabaseError\")<{\n  readonly operation: string;\n  readonly details: string;\n}> {}\n\nclass ValidationError extends Data.TaggedError(\"ValidationError\")<{\n  readonly field: string;\n  readonly message: string;\n}> {}\n\n// Define database service\nclass DatabaseService extends Effect.Service<DatabaseService>()(\n  \"DatabaseService\",\n  {\n    sync: () => ({\n      // Connect to database with proper error handling\n      connect: (config: DatabaseConfig): Effect.Effect<DatabaseConnection, DatabaseError> =>\n        Effect.gen(function* () {\n          yield* Effect.logInfo(`Connecting to database: ${config.url}`);\n          \n          if (!config.url) {\n            const error = new DatabaseError({\n              operation: \"connect\",\n              details: \"Missing URL\"\n            });\n            yield* Effect.logError(`Database error: ${JSON.stringify(error)}`);\n            return yield* Effect.fail(error);\n          }\n          \n          // Simulate unexpected errors\n          if (config.url === \"invalid\") {\n            yield* Effect.logError(\"Invalid connection string\");\n            return yield* Effect.sync(() => {\n              throw new Error(\"Failed to parse connection string\");\n            });\n          }\n          \n          if (config.url === \"timeout\") {\n            yield* Effect.logError(\"Connection timeout\");\n            return yield* Effect.sync(() => {\n              throw new Error(\"Connection timed out\");\n            });\n          }\n          \n          yield* Effect.logInfo(\"Database connection successful\");\n          return { success: true };\n        })\n    })\n  }\n) {}\n\n// Define user service\nclass UserService extends Effect.Service<UserService>()(\n  \"UserService\",\n  {\n    sync: () => ({\n      // Parse user data with validation\n      parseUser: (input: unknown): Effect.Effect<UserData, ValidationError> =>\n        Effect.gen(function* () {\n          yield* Effect.logInfo(`Parsing user data: ${JSON.stringify(input)}`);\n          \n          try {\n            if (typeof input !== \"object\" || !input) {\n              const error = new ValidationError({\n                field: \"input\",\n                message: \"Invalid input type\"\n              });\n              yield* Effect.logWarning(`Validation error: ${JSON.stringify(error)}`);\n              throw error;\n            }\n            \n            const data = input as Record<string, unknown>;\n            \n            if (typeof data.id !== \"string\" || typeof data.name !== \"string\") {\n              const error = new ValidationError({\n                field: \"input\",\n                message: \"Missing required fields\"\n              });\n              yield* Effect.logWarning(`Validation error: ${JSON.stringify(error)}`);\n              throw error;\n            }\n            \n            const user = { id: data.id, name: data.name };\n            yield* Effect.logInfo(`Successfully parsed user: ${JSON.stringify(user)}`);\n            return user;\n          } catch (e) {\n            if (e instanceof ValidationError) {\n              return yield* Effect.fail(e);\n            }\n            yield* Effect.logError(`Unexpected error: ${e instanceof Error ? e.message : String(e)}`);\n            throw e;\n          }\n        })\n    })\n  }\n) {}\n\n// Define test service\nclass TestService extends Effect.Service<TestService>()(\n  \"TestService\",\n  {\n    sync: () => {\n      // Create instance methods\n      const printCause = (prefix: string, cause: Cause.Cause<unknown>): Effect.Effect<void, never, never> =>\n        Effect.gen(function* () {\n          yield* Effect.logInfo(`\\n=== ${prefix} ===`);\n          \n          if (Cause.isDie(cause)) {\n            const defect = Cause.failureOption(cause);\n            if (defect._tag === \"Some\") {\n              const error = defect.value as Error;\n              yield* Effect.logError(\"Defect (unexpected error)\");\n              yield* Effect.logError(`Message: ${error.message}`);\n              yield* Effect.logError(`Stack: ${error.stack?.split('\\n')[1]?.trim() ?? 'N/A'}`);\n            }\n          } else if (Cause.isFailure(cause)) {\n            const error = Cause.failureOption(cause);\n            yield* Effect.logWarning(\"Expected failure\");\n            yield* Effect.logWarning(`Error: ${JSON.stringify(error)}`);\n          }\n\n          return Effect.succeed(void 0);\n        });\n\n      const runScenario = <E, A extends { [key: string]: any }>(\n        name: string,\n        program: Effect.Effect<A, E>\n      ): Effect.Effect<void, never, never> =>\n        Effect.gen(function* () {\n          yield* Effect.logInfo(`\\n=== Testing: ${name} ===`);\n          \n          type TestError = { readonly _tag: \"error\"; readonly cause: Cause.Cause<E> };\n          \n          const result = yield* Effect.catchAllCause(\n            program,\n            (cause) => Effect.succeed({ _tag: \"error\" as const, cause } as TestError)\n          );\n          \n          if (\"cause\" in result) {\n            yield* printCause(\"Error details\", result.cause);\n          } else {\n            yield* Effect.logInfo(`Success: ${JSON.stringify(result)}`);\n          }\n\n          return Effect.succeed(void 0);\n        });\n\n      // Return bound methods\n      return {\n        printCause,\n        runScenario\n      };\n    }\n  }\n) {}\n\n// Create program with proper error handling\nconst program = Effect.gen(function* () {\n  const db = yield* DatabaseService;\n  const users = yield* UserService;\n  const test = yield* TestService;\n  \n  yield* Effect.logInfo(\"=== Starting Error Handling Tests ===\");\n  \n  // Test expected database errors\n  yield* test.runScenario(\n    \"Expected database error\",\n    Effect.gen(function* () {\n      const result = yield* Effect.retry(\n        db.connect({ url: \"\" }),\n        Schedule.exponential(100)\n      ).pipe(\n        Effect.timeout(Duration.seconds(5)),\n        Effect.catchAll(() => Effect.fail(\"Connection timeout\"))\n      );\n      return result;\n    })\n  );\n  \n  // Test unexpected connection errors\n  yield* test.runScenario(\n    \"Unexpected connection error\",\n    Effect.gen(function* () {\n      const result = yield* Effect.retry(\n        db.connect({ url: \"invalid\" }),\n        Schedule.recurs(3)\n      ).pipe(\n        Effect.catchAllCause(cause =>\n          Effect.gen(function* () {\n            yield* Effect.logError(\"Failed after 3 retries\");\n            yield* Effect.logError(Cause.pretty(cause));\n            return yield* Effect.fail(\"Max retries exceeded\");\n          })\n        )\n      );\n      return result;\n    })\n  );\n  \n  // Test user validation with recovery\n  yield* test.runScenario(\n    \"Valid user data\",\n    Effect.gen(function* () {\n      const result = yield* users.parseUser({ id: \"1\", name: \"John\" }).pipe(\n        Effect.orElse(() => \n          Effect.succeed({ id: \"default\", name: \"Default User\" })\n        )\n      );\n      return result;\n    })\n  );\n  \n  // Test concurrent error handling with timeout\n  yield* test.runScenario(\n    \"Concurrent operations\",\n    Effect.gen(function* () {\n      const results = yield* Effect.all([\n        db.connect({ url: \"\" }).pipe(\n          Effect.timeout(Duration.seconds(1)),\n          Effect.catchAll(() => Effect.succeed({ success: true }))\n        ),\n        users.parseUser({ id: \"invalid\" }).pipe(\n          Effect.timeout(Duration.seconds(1)),\n          Effect.catchAll(() => Effect.succeed({ id: \"timeout\", name: \"Timeout\" }))\n        )\n      ], { concurrency: 2 });\n      return results;\n    })\n  );\n  \n  yield* Effect.logInfo(\"\\n=== Error Handling Tests Complete ===\");\n\n  return Effect.succeed(void 0);\n});\n\n// Run the program with all services\nEffect.runPromise(\n  Effect.provide(\n    Effect.provide(\n      Effect.provide(\n        program,\n        TestService.Default\n      ),\n      DatabaseService.Default\n    ),\n    UserService.Default\n  )\n);\n```\n\n**Explanation:**  \nBy inspecting the `Cause`, you can distinguish between expected and unexpected\nfailures, logging or escalating as appropriate."
  },
  {
    "path": "rules/cursor/implement-graceful-shutdown-for-your-application.mdc",
    "contents": "description: Use Effect.runFork and OS signal listeners to implement graceful shutdown for long-running applications.\nglobs: \"**/*.ts\"\nalwaysApply: true\n\n# Implement Graceful Shutdown for Your Application\n**Rule:** Use Effect.runFork and OS signal listeners to implement graceful shutdown for long-running applications.\n\n### Example\nThis example creates a server with a \"scoped\" database connection. It uses `runFork` to start the server and sets up a `SIGINT` handler to interrupt the server fiber, which in turn guarantees the database finalizer is called.\n\n```typescript\nimport { Effect, Layer, Fiber, Context, Scope } from \"effect\";\nimport * as http from \"http\";\n\n// 1. A service with a finalizer for cleanup\nclass Database extends Effect.Service<Database>()(\"Database\", {\n  effect: Effect.gen(function* () {\n    yield* Effect.log(\"Acquiring DB connection\");\n    return {\n      query: () => Effect.succeed(\"data\"),\n    };\n  }),\n}) {}\n\n// 2. The main server logic\nconst server = Effect.gen(function* () {\n  const db = yield* Database;\n\n  // Create server with proper error handling\n  const httpServer = yield* Effect.sync(() => {\n    const server = http.createServer((_req, res) => {\n      Effect.runFork(\n        Effect.provide(\n          db.query().pipe(Effect.map((data) => res.end(data))),\n          Database.Default\n        )\n      );\n    });\n    return server;\n  });\n\n  // Add a finalizer to close the server\n  yield* Effect.addFinalizer(() =>\n    Effect.sync(() => {\n      httpServer.close();\n      console.log(\"Server closed\");\n    })\n  );\n\n  // Start server with error handling\n  yield* Effect.async<void, Error>((resume) => {\n    httpServer.once('error', (err: Error) => {\n      resume(Effect.fail(new Error(`Failed to start server: ${err.message}`)));\n    });\n\n    httpServer.listen(3456, () => {\n      resume(Effect.succeed(void 0));\n    });\n  });\n\n  yield* Effect.log(\"Server started on port 3456. Press Ctrl+C to exit.\");\n\n  // For testing purposes, we'll run for a short time instead of forever\n  yield* Effect.sleep(\"2 seconds\");\n  yield* Effect.log(\"Shutting down gracefully...\");\n});\n\n// 3. Provide the layer and launch with runFork\nconst app = Effect.provide(server.pipe(Effect.scoped), Database.Default);\n\n// 4. Run the app and handle shutdown\nEffect.runPromise(app).catch((error) => {\n  console.error(\"Application error:\", error);\n  process.exit(1);\n});\n\n```\n\n---"
  },
  {
    "path": "rules/cursor/manage-resource-lifecycles-with-scope.mdc",
    "contents": "description: Use Scope for fine-grained, manual control over resource lifecycles and cleanup guarantees.\nglobs: \"**/*.ts\"\nalwaysApply: true\n\n# Manage Resource Lifecycles with Scope\n**Rule:** Use Scope for fine-grained, manual control over resource lifecycles and cleanup guarantees.\n\n### Example\nThis example shows how to acquire a resource (like a file handle), use it, and have `Scope` guarantee its release.\n\n```typescript\nimport { Effect, Scope } from \"effect\";\n\n// Simulate acquiring and releasing a resource\nconst acquireFile = Effect.log(\"File opened\").pipe(\n  Effect.as({ write: (data: string) => Effect.log(`Wrote: ${data}`) }),\n);\nconst releaseFile = Effect.log(\"File closed.\");\n\n// Create a \"scoped\" effect. This effect, when used, will acquire the\n// resource and register its release action with the current scope.\nconst scopedFile = Effect.acquireRelease(acquireFile, () => releaseFile);\n\n// The main program that uses the scoped resource\nconst program = Effect.gen(function* () {\n  // Effect.scoped \"uses\" the resource. It runs the acquire effect,\n  // provides the resource to the inner effect, and ensures the\n  // release effect is run when this block completes.\n  const file = yield* Effect.scoped(scopedFile);\n\n  yield* file.write(\"hello\");\n  yield* file.write(\"world\");\n\n  // The file will be automatically closed here.\n});\n\nEffect.runPromise(program);\n/*\nOutput:\nFile opened\nWrote: hello\nWrote: world\nFile closed\n*/\n```\n\n---"
  },
  {
    "path": "rules/cursor/manage-resources-safely-in-a-pipeline.mdc",
    "contents": "description: Use Stream.acquireRelease to safely manage the lifecycle of a resource within a pipeline.\nglobs: \"**/*.ts\"\nalwaysApply: true\n\n# Manage Resources Safely in a Pipeline\n**Rule:** Use Stream.acquireRelease to safely manage the lifecycle of a resource within a pipeline.\n\n### Example\nThis example creates and writes to a temporary file. `Stream.acquireRelease` is used to acquire a readable stream from that file. The pipeline then processes the file but is designed to fail partway through. The logs demonstrate that the `release` effect (which deletes the file) is still executed, preventing any resource leaks.\n\n```typescript\nimport { Effect, Layer } from \"effect\";\nimport { FileSystem } from \"@effect/platform/FileSystem\";\nimport { NodeFileSystem } from \"@effect/platform-node\";\nimport * as path from \"node:path\";\n\ninterface ProcessError {\n  readonly _tag: \"ProcessError\";\n  readonly message: string;\n}\n\nconst ProcessError = (message: string): ProcessError => ({\n  _tag: \"ProcessError\",\n  message,\n});\n\ninterface FileServiceType {\n  readonly createTempFile: () => Effect.Effect<{ filePath: string }, never>;\n  readonly cleanup: (filePath: string) => Effect.Effect<void, never>;\n  readonly readFile: (filePath: string) => Effect.Effect<string, never>;\n}\n\nexport class FileService extends Effect.Service<FileService>()(\"FileService\", {\n  sync: () => {\n    const filePath = path.join(__dirname, \"temp-resource.txt\");\n    return {\n      createTempFile: () => Effect.succeed({ filePath }),\n      cleanup: (filePath: string) =>\n        Effect.sync(() => console.log(\"\u2705 Resource cleaned up successfully\")),\n      readFile: (filePath: string) =>\n        Effect.succeed(\"data 1\\ndata 2\\nFAIL\\ndata 4\"),\n    };\n  },\n}) {}\n\n// Process a single line\nconst processLine = (line: string): Effect.Effect<void, ProcessError> =>\n  line === \"FAIL\"\n    ? Effect.fail(ProcessError(\"Failed to process line\"))\n    : Effect.sync(() => console.log(`Processed: ${line}`));\n\n// Create and process the file with proper resource management\nconst program = Effect.gen(function* () {\n  console.log(\"=== Stream Resource Management Demo ===\");\n  console.log(\n    \"This demonstrates proper resource cleanup even when errors occur\"\n  );\n\n  const fileService = yield* FileService;\n  const { filePath } = yield* fileService.createTempFile();\n\n  // Use scoped to ensure cleanup happens even on failure\n  yield* Effect.scoped(\n    Effect.gen(function* () {\n      yield* Effect.addFinalizer(() => fileService.cleanup(filePath));\n\n      const content = yield* fileService.readFile(filePath);\n      const lines = content.split(\"\\n\");\n\n      // Process each line, continuing even if some fail\n      for (const line of lines) {\n        yield* processLine(line).pipe(\n          Effect.catchAll((error) =>\n            Effect.sync(() =>\n              console.log(`\u26a0\ufe0f  Skipped line due to error: ${error.message}`)\n            )\n          )\n        );\n      }\n\n      console.log(\"\u2705 Processing completed with proper resource management\");\n    })\n  );\n});\n\n// Run the program with FileService layer\nEffect.runPromise(Effect.provide(program, FileService.Default)).catch(\n  (error) => {\n    console.error(\"Unexpected error:\", error);\n  }\n);\n\n```"
  },
  {
    "path": "rules/cursor/manually-manage-lifecycles-with-scope.mdc",
    "contents": "description: Use `Effect.scope` and `Scope.addFinalizer` for fine-grained control over resource cleanup.\nglobs: \"**/*.ts\"\nalwaysApply: true\n\n# Manually Manage Lifecycles with `Scope`\n**Rule:** Use `Effect.scope` and `Scope.addFinalizer` for fine-grained control over resource cleanup.\n\n### Example\n```typescript\nimport { Effect, Console } from \"effect\";\n\n// Mocking a complex file operation\nconst openFile = (path: string) =>\n  Effect.succeed({ path, handle: Math.random() }).pipe(\n    Effect.tap((f) => Console.log(`Opened ${f.path}`)),\n  );\nconst createTempFile = (path: string) =>\n  Effect.succeed({ path: `${path}.tmp`, handle: Math.random() }).pipe(\n    Effect.tap((f) => Console.log(`Created temp file ${f.path}`)),\n  );\nconst closeFile = (file: { path: string }) =>\n  Effect.sync(() => Console.log(`Closed ${file.path}`));\nconst deleteFile = (file: { path: string }) =>\n  Effect.sync(() => Console.log(`Deleted ${file.path}`));\n\n// This program acquires two resources (a file and a temp file)\n// and ensures both are cleaned up correctly using acquireRelease.\nconst program = Effect.gen(function* () {\n  const file = yield* Effect.acquireRelease(\n    openFile(\"data.csv\"),\n    (f) => closeFile(f)\n  );\n\n  const tempFile = yield* Effect.acquireRelease(\n    createTempFile(\"data.csv\"),\n    (f) => deleteFile(f)\n  );\n\n  yield* Console.log(\"...writing data from temp file to main file...\");\n});\n\n// Run the program with a scope\nEffect.runPromise(Effect.scoped(program));\n\n/*\nOutput (note the LIFO cleanup order):\nOpened data.csv\nCreated temp file data.csv.tmp\n...writing data from temp file to main file...\nDeleted data.csv.tmp\nClosed data.csv\n*/\n```\n\n**Explanation:**\n`Effect.scope` creates a new `Scope` and provides it to the `program`. Inside `program`, we access this `Scope` and use `addFinalizer` to register cleanup actions immediately after acquiring each resource. When `Effect.scope` finishes executing `program`, it closes the scope, which in turn executes all registered finalizers in the reverse order of their addition."
  },
  {
    "path": "rules/cursor/organize-layers-into-composable-modules.mdc",
    "contents": "description: Organize services into modular Layers that are composed hierarchically to manage complexity in large applications.\nglobs: \"**/*.ts\"\nalwaysApply: true\n\n# Organize Layers into Composable Modules\n**Rule:** Organize services into modular Layers that are composed hierarchically to manage complexity in large applications.\n\n### Example\nThis example shows a `BaseLayer` with a `Logger`, a `UserModule` that uses the `Logger`, and a final `AppLayer` that wires them together.\n\n### 1. The Base Infrastructure Layer\n\n```typescript\n// src/core/Logger.ts\nimport { Effect } from \"effect\";\n\nexport class Logger extends Effect.Service<Logger>()(\n  \"App/Core/Logger\",\n  {\n    sync: () => ({\n      log: (msg: string) => Effect.sync(() => console.log(`[LOG] ${msg}`))\n    })\n  }\n) {}\n\n// src/features/User/UserRepository.ts\nexport class UserRepository extends Effect.Service<UserRepository>()(\n  \"App/User/UserRepository\",\n  {\n    // Define implementation that uses Logger\n    effect: Effect.gen(function* () {\n      const logger = yield* Logger;\n      return {\n        findById: (id: number) =>\n          Effect.gen(function* () {\n            yield* logger.log(`Finding user ${id}`);\n            return { id, name: `User ${id}` };\n          })\n      };\n    }),\n    // Declare Logger dependency\n    dependencies: [Logger.Default]\n  }\n) {}\n\n// Example usage\nconst program = Effect.gen(function* () {\n  const repo = yield* UserRepository;\n  const user = yield* repo.findById(1);\n  return user;\n});\n\n// Run with default implementations\nEffect.runPromise(\n  Effect.provide(\n    program,\n    UserRepository.Default\n  )\n).then(console.log);\n```\n\n### 2. The Feature Module Layer\n\n```typescript\n// src/core/Logger.ts\nimport { Effect } from \"effect\";\n\nexport class Logger extends Effect.Service<Logger>()(\n  \"App/Core/Logger\",\n  {\n    sync: () => ({\n      log: (msg: string) => Effect.sync(() => console.log(`[LOG] ${msg}`))\n    })\n  }\n) {}\n\n// src/features/User/UserRepository.ts\nexport class UserRepository extends Effect.Service<UserRepository>()(\n  \"App/User/UserRepository\",\n  {\n    // Define implementation that uses Logger\n    effect: Effect.gen(function* () {\n      const logger = yield* Logger;\n      return {\n        findById: (id: number) =>\n          Effect.gen(function* () {\n            yield* logger.log(`Finding user ${id}`);\n            return { id, name: `User ${id}` };\n          })\n      };\n    }),\n    // Declare Logger dependency\n    dependencies: [Logger.Default]\n  }\n) {}\n\n// Example usage\nconst program = Effect.gen(function* () {\n  const repo = yield* UserRepository;\n  const user = yield* repo.findById(1);\n  return user;\n});\n\n// Run with default implementations\nEffect.runPromise(\n  Effect.provide(\n    program,\n    UserRepository.Default\n  )\n).then(console.log);\n```\n\n### 3. The Final Application Composition\n\n```typescript\n// src/layers.ts\nimport { Layer } from \"effect\";\nimport { BaseLayer } from \"./core\";\nimport { UserModuleLive } from \"./features/User\";\n// import { ProductModuleLive } from \"./features/Product\";\n\nconst AllModules = Layer.mergeAll(UserModuleLive /*, ProductModuleLive */);\n\n// Provide the BaseLayer to all modules at once, creating a self-contained AppLayer.\nexport const AppLayer = Layer.provide(AllModules, BaseLayer);\n```\n\n---"
  },
  {
    "path": "rules/cursor/poll-for-status-until-a-task-completes.mdc",
    "contents": "description: Use Effect.race to run a repeating polling task that is automatically interrupted when a main task completes.\nglobs: \"**/*.ts\"\nalwaysApply: true\n\n# Poll for Status Until a Task Completes\n**Rule:** Use Effect.race to run a repeating polling task that is automatically interrupted when a main task completes.\n\n### Example\nThis program simulates a long-running data processing job. While it's running, a separate effect polls for its status every 2 seconds. When the main job finishes after 10 seconds, the polling automatically stops.\n\n```typescript\nimport { Effect, Schedule, Duration } from \"effect\";\n\n// The main task that takes a long time to complete\nconst longRunningJob = Effect.log(\"Data processing complete!\").pipe(\n  Effect.delay(Duration.seconds(10)),\n);\n\n// The polling task that checks the status\nconst pollStatus = Effect.log(\"Polling for job status: In Progress...\");\n\n// A schedule that repeats the polling task every 2 seconds, forever\nconst pollingSchedule = Schedule.fixed(Duration.seconds(2));\n\n// The complete polling effect that will run indefinitely until interrupted\nconst repeatingPoller = pollStatus.pipe(Effect.repeat(pollingSchedule));\n\n// Race the main job against the poller.\n// The longRunningJob will win after 10 seconds, interrupting the poller.\nconst program = Effect.race(longRunningJob, repeatingPoller);\n\nEffect.runPromise(program);\n/*\nOutput:\nPolling for job status: In Progress...\nPolling for job status: In Progress...\nPolling for job status: In Progress...\nPolling for job status: In Progress...\nPolling for job status: In Progress...\nData processing complete!\n*/\n```\n\n---"
  },
  {
    "path": "rules/cursor/run-background-tasks-with-effect-fork.mdc",
    "contents": "description: Use Effect.fork to start a non-blocking background process and manage its lifecycle via its Fiber.\nglobs: \"**/*.ts\"\nalwaysApply: true\n\n# Run Background Tasks with Effect.fork\n**Rule:** Use Effect.fork to start a non-blocking background process and manage its lifecycle via its Fiber.\n\n### Example\nThis program forks a background process that logs a \"tick\" every second. The main process does its own work for 5 seconds and then explicitly interrupts the background logger before exiting.\n\n```typescript\nimport { Effect, Fiber } from \"effect\";\n\n// A long-running effect that logs a message every second, forever\n// Effect.forever creates an infinite loop that repeats the effect\n// This simulates a background service like a health check or monitoring task\nconst tickingClock = Effect.log(\"tick\").pipe(\n  Effect.delay(\"1 second\"), // Wait 1 second between ticks\n  Effect.forever, // Repeat indefinitely - this creates an infinite effect\n);\n\nconst program = Effect.gen(function* () {\n  yield* Effect.log(\"Forking the ticking clock into the background.\");\n  \n  // Start the clock, but don't wait for it.\n  // Effect.fork creates a new fiber that runs concurrently with the main program\n  // The main fiber continues immediately without waiting for the background task\n  // This is essential for non-blocking background operations\n  const clockFiber = yield* Effect.fork(tickingClock);\n  \n  // At this point, we have two fibers running:\n  // 1. The main fiber (this program)\n  // 2. The background clock fiber (ticking every second)\n\n  yield* Effect.log(\"Main process is now doing other work for 5 seconds...\");\n  \n  // Simulate the main application doing work\n  // While this sleep happens, the background clock continues ticking\n  // This demonstrates true concurrency - both fibers run simultaneously\n  yield* Effect.sleep(\"5 seconds\");\n\n  yield* Effect.log(\"Main process is done. Interrupting the clock fiber.\");\n  \n  // Stop the background process.\n  // Fiber.interrupt sends an interruption signal to the fiber\n  // This allows the fiber to perform cleanup operations before terminating\n  // Without this, the background task would continue running indefinitely\n  yield* Fiber.interrupt(clockFiber);\n  \n  // Important: Always clean up background fibers to prevent resource leaks\n  // In a real application, you might want to:\n  // 1. Use Fiber.join instead of interrupt to wait for graceful completion\n  // 2. Handle interruption signals within the background task\n  // 3. Implement proper shutdown procedures\n\n  yield* Effect.log(\"Program finished.\");\n  \n  // Key concepts demonstrated:\n  // 1. Fork creates concurrent fibers without blocking\n  // 2. Background tasks run independently of the main program\n  // 3. Fiber interruption provides controlled shutdown\n  // 4. Multiple fibers can run simultaneously on the same thread pool\n});\n\n// This example shows how to:\n// - Run background tasks that don't block the main program\n// - Manage fiber lifecycles (create, run, interrupt)\n// - Coordinate between multiple concurrent operations\n// - Properly clean up resources when shutting down\nEffect.runPromise(program);\n```\n\n---"
  },
  {
    "path": "rules/cursor/teach-your-ai-agents-effect-with-the-mcp-server.mdc",
    "contents": "description: Use the MCP server to provide live application context to AI coding agents, enabling more accurate assistance.\nglobs: \"**/*.ts\"\nalwaysApply: true\n\n# Teach your AI Agents Effect with the MCP Server\n**Rule:** Use the MCP server to provide live application context to AI coding agents, enabling more accurate assistance.\n\n### Example\nThe \"Good Example\" is the workflow this pattern enables.\n\n1.  **You run the MCP server** in your terminal, pointing it at your main `AppLayer`.\n    ```bash\n    npx @effect/mcp-server --layer src/layers.ts:AppLayer\n    ```\n\n2.  **You configure your AI agent** (e.g., Cursor) to use the MCP server's endpoint (`http://localhost:3333`).\n\n3.  **You ask the AI a question** that requires deep context about your app:\n    > \"Refactor this code to use the `UserService` to fetch a user by ID and log the result with the `Logger`.\"\n\n4.  **The AI, in the background, queries the MCP server:**\n    -   It discovers that `UserService` and `Logger` are available in the `AppLayer`.\n    -   It retrieves the exact method signature for `UserService.getUser` and `Logger.log`.\n\n5.  **The AI generates correct, context-aware code** because it's not guessing; it's using the live architectural information provided by the MCP server.\n\n```typescript\n// The AI generates this correct code:\nimport { Effect } from \"effect\";\nimport { UserService } from \"./features/User/UserService\";\nconst program = Effect.gen(function* () {\n  const userService = yield* UserService;\n\n  const user = yield* userService.getUser(\"123\");\n  yield* Effect.log(`Found user: ${user.name}`);\n});\n```\n\n---"
  },
  {
    "path": "rules/cursor/understand-fibers-as-lightweight-threads.mdc",
    "contents": "description: Understand that a Fiber is a lightweight, virtual thread managed by the Effect runtime for massive concurrency.\nglobs: \"**/*.ts\"\nalwaysApply: true\n\n# Understand Fibers as Lightweight Threads\n**Rule:** Understand that a Fiber is a lightweight, virtual thread managed by the Effect runtime for massive concurrency.\n\n### Example\nThis program demonstrates the efficiency of fibers by forking 100,000 of them. Each fiber does a small amount of work (sleeping for 1 second). Trying to do this with 100,000 OS threads would instantly crash any system.\n\n```typescript\nimport { Effect, Fiber } from \"effect\";\n\nconst program = Effect.gen(function* () {\n  // Demonstrate the lightweight nature of fibers by creating 100,000 of them\n  // This would be impossible with OS threads due to memory and context switching overhead\n  const fiberCount = 100_000;\n  yield* Effect.log(`Forking ${fiberCount} fibers...`);\n\n  // Create an array of 100,000 simple effects\n  // Each effect sleeps for 1 second and then returns its index\n  // This simulates lightweight concurrent tasks\n  const tasks = Array.from({ length: fiberCount }, (_, i) =>\n    Effect.sleep(\"1 second\").pipe(Effect.as(i))\n  );\n\n  // Fork all of them into background fibers\n  // Effect.fork creates a new fiber for each task without blocking\n  // This demonstrates fiber creation scalability - 100k fibers created almost instantly\n  // Each fiber is much lighter than an OS thread (typically ~1KB vs ~8MB per thread)\n  const fibers = yield* Effect.forEach(tasks, Effect.fork);\n\n  yield* Effect.log(\n    \"All fibers have been forked. Now waiting for them to complete...\"\n  );\n\n  // Wait for all fibers to finish their work\n  // Fiber.joinAll waits for all fibers to complete and collects their results\n  // This demonstrates fiber coordination - managing thousands of concurrent operations\n  // The runtime efficiently schedules these fibers using a work-stealing thread pool\n  const results = yield* Fiber.joinAll(fibers);\n\n  yield* Effect.log(`All ${results.length} fibers have completed.`);\n\n  // Key insights from this example:\n  // 1. Fibers are extremely lightweight - 100k fibers use minimal memory\n  // 2. Fiber creation is fast - no expensive OS thread allocation\n  // 3. The Effect runtime efficiently schedules fibers across available CPU cores\n  // 4. Fibers can be suspended and resumed without blocking OS threads\n  // 5. This enables massive concurrency for I/O-bound operations\n});\n\n// This program runs successfully, demonstrating the low overhead of fibers.\n// Try running this with OS threads - you'd likely hit system limits around 1000-10000 threads\n// With fibers, 100k+ concurrent operations are easily achievable\nEffect.runPromise(program);\n\n```\n\n---"
  }
]