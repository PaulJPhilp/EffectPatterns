---
id: schema-ai-output-unions-for-ai
title: Union Types for Flexible Outputs
category: ai-schemas
skillLevel: intermediate
tags:
  - schema
  - ai
  - unions
  - discriminated-unions
  - polymorphism
lessonOrder: 35
rule:
  description: >-
    Union Types for Flexible Outputs using Schema.
---

# Problem

An LLM needs to return different response shapes depending on context. For example, a query might succeed with data, fail with an error, or be pending. Without union types, you either get a flat schema with optional fields or lose type safety. You need discriminated unions so the LLM knows what to output and TypeScript knows what to expect.

# Solution

```typescript
import { Schema, JSONSchema, Effect } from "effect"
import { Anthropic } from "@anthropic-ai/sdk"

// 1. Define success response
const SuccessResponse = Schema.Struct({
  type: Schema.Literal("success"),
  data: Schema.Struct({
    id: Schema.String,
    name: Schema.String,
    email: Schema.String.pipe(
      Schema.pattern(/^[^\s@]+@[^\s@]+\.[^\s@]+$/)
    ),
    score: Schema.Number.pipe(Schema.between(0, 100)),
  }),
  timestamp: Schema.String.pipe(
    Schema.description("ISO 8601 timestamp")
  ),
})

// 2. Define error response
const ErrorResponse = Schema.Struct({
  type: Schema.Literal("error"),
  error: Schema.Struct({
    code: Schema.Literal("not_found", "invalid_input", "server_error"),
    message: Schema.String,
    details: Schema.String.pipe(Schema.optional),
  }),
  timestamp: Schema.String,
})

// 3. Define pending response
const PendingResponse = Schema.Struct({
  type: Schema.Literal("pending"),
  requestId: Schema.String,
  estimatedWaitSeconds: Schema.Number.pipe(
    Schema.description("How long user should wait before retrying")
  ),
  timestamp: Schema.String,
})

// 4. Create discriminated union
const QueryResponse = Schema.Union(
  SuccessResponse,
  ErrorResponse,
  PendingResponse
).pipe(
  Schema.description("Response type determined by 'type' field")
)

type QueryResponse = typeof QueryResponse.Type

// 5. Generate JSON Schema showing all variants
const jsonSchema = JSONSchema.make(QueryResponse)

// 6. Use in LLM call
const queryLLM = (query: string) =>
  Effect.gen(function* () {
    const client = new Anthropic()

    const response = yield* Effect.tryPromise({
      try: () =>
        client.messages.create({
          model: "claude-3-5-sonnet-20241022",
          max_tokens: 1024,
          messages: [
            {
              role: "user",
              content: `Process query and respond with appropriate structure:\n\n${query}`,
            },
          ],
          tools: [
            {
              name: "query_response",
              description: "Response with success/error/pending states",
              input_schema: jsonSchema as any,
            },
          ],
        }),
      catch: (error) => new Error(`API call failed: ${error}`),
    })

    const toolUse = response.content.find(
      (block) => block.type === "tool_use"
    ) as any

    if (!toolUse) {
      return yield* Effect.fail(new Error("No tool use in response"))
    }

    // Schema.decodeUnknownSync handles discriminated union
    const result = yield* Effect.tryPromise({
      try: () => Schema.decodeUnknownSync(QueryResponse)(toolUse.input),
      catch: (error) => new Error(`Invalid response: ${error}`),
    })

    return result
  })

// 7. Type-safe pattern matching
const handleResponse = (response: QueryResponse): string => {
  switch (response.type) {
    case "success":
      return `âœ… Found: ${response.data.name} (${response.data.email})`

    case "error":
      if (response.error.code === "not_found") {
        return `âŒ Not found: ${response.error.message}`
      }
      if (response.error.code === "invalid_input") {
        return `âš ï¸ Invalid: ${response.error.message}`
      }
      return `ðŸ”¥ Error: ${response.error.message}`

    case "pending":
      return `â³ Pending (retry in ${response.estimatedWaitSeconds}s)`
  }
}

// Usage example 1: Success case
const successQuery = "Find user with email john@example.com"
Effect.runPromise(queryLLM(successQuery)).then((response) => {
  console.log(handleResponse(response))

  // Type narrowing: TypeScript knows this is SuccessResponse
  if (response.type === "success") {
    console.log(`Score: ${response.data.score}/100`)
  }
})

// Usage example 2: Error case
const errorQuery = "Find user with invalid ID xyz"
Effect.runPromise(queryLLM(errorQuery)).then((response) => {
  console.log(handleResponse(response))

  // Type narrowing works here too
  if (response.type === "error") {
    console.log(`Error code: ${response.error.code}`)
  }
})
```

# Why This Works

| Concept | Explanation |
|---------|-------------|
| Discriminated unions | `type` field determines which variant; LLM sees all options in schema |
| `Schema.Union` | Combines multiple possible shapes; validates against all variants |
| Type narrowing | `switch(response.type)` narrows type in each case |
| Exhaustiveness check | TypeScript warns if you forget a case |
| JSON Schema clarity | Each variant visible to LLM with its own fields |

# When to Use

- Success/error/pending responses
- Query results that might be incomplete or fail
- Polymorphic API responses
- When different branches require different data
- States with different transition logic (e.g., draft/published/archived)

# Related Patterns

- [Basic AI Output Schema](./basic.md)
- [Enums and Literal Types](./enums-and-literals.md)
- [Nested Object Schemas](./nested-structures.md)
- [Integration with Vercel AI SDK](./vercel-ai-sdk.md)
