---
id: schema-ai-parsing-retry-on-failure
title: Retry Strategies for Parse Failures
category: ai-schemas
skill: intermediate
tags:
  - schema
  - ai
  - retry
  - backoff
  - resilience
  - exponential-backoff
lessonOrder: 30
---

# Problem

Parsing an LLM response fails—maybe the model hallucinated, generated malformed JSON, or the response was incomplete. Retrying with a fresh API call might succeed. You need to distinguish retryable failures (network, temporary malformation) from permanent ones (schema incompatibility), then retry intelligently without spinning in a loop or timing out.

# Solution

```typescript
import {
  Effect,
  Schema,
  Schedule,
  Random,
} from "effect"
import { Anthropic } from "@anthropic-ai/sdk"

// 1. Define retryable and permanent errors
type ParseError =
  | { _tag: "InvalidJSON"; message: string }
  | { _tag: "SchemaViolation"; message: string }
  | { _tag: "NetworkError"; message: string }
  | { _tag: "Timeout"; message: string }

const isRetryable = (error: ParseError): boolean => {
  return (
    error._tag === "NetworkError" ||
    error._tag === "Timeout"
  )
}

// 2. Define schema
const Response = Schema.Struct({
  result: Schema.String,
  confidence: Schema.Number.pipe(
    Schema.between(0, 1)
  ),
})

type Response = typeof Response.Type

// 3. Parse with error categorization
const parseResponse = (data: unknown) =>
  Effect.gen(function* () {
    try {
      const parsed = yield* Schema.decodeUnknown(
        Response
      )(data)
      return { _tag: "Success" as const, data: parsed }
    } catch (error) {
      // Categorize error
      const message = String(error)

      if (message.includes("JSON")) {
        return {
          _tag: "ParseFail" as const,
          error: {
            _tag: "InvalidJSON" as const,
            message,
          },
        }
      }

      if (
        message.includes("confidence") ||
        message.includes("between")
      ) {
        return {
          _tag: "ParseFail" as const,
          error: {
            _tag: "SchemaViolation" as const,
            message,
          },
        }
      }

      return {
        _tag: "ParseFail" as const,
        error: {
          _tag: "NetworkError" as const,
          message,
        },
      }
    }
  })

// 4. Retry strategy: exponential backoff with jitter
const callLLMWithRetry = (prompt: string) =>
  Effect.gen(function* () {
    const client = new Anthropic()

    // Exponential backoff: 100ms → 200ms → 400ms → 800ms (max 5s)
    const schedule = Schedule.exponential(
      "100 millis"
    ).pipe(
      Schedule.map(() =>
        Effect.gen(function* () {
          // Add jitter to prevent thundering herd
          const jitter = yield* Random.nextIntBetween(
            0,
            100
          )
          return jitter
        }).pipe(Effect.runSync())
      ),
      Schedule.compose(
        Schedule.recurUntil(
          (attempt) => attempt >= 3
        )
      )
    )

    const callLLM = () =>
      Effect.gen(function* () {
        const response = yield* Effect.tryPromise({
          try: () =>
            client.messages.create({
              model: "claude-3-5-sonnet-20241022",
              max_tokens: 1024,
              messages: [
                { role: "user", content: prompt },
              ],
            }),
          catch: (error) => {
            const msg = String(error)
            if (msg.includes("timeout")) {
              return {
                _tag: "Timeout" as const,
                message: msg,
              }
            }
            return {
              _tag: "NetworkError" as const,
              message: msg,
            }
          },
        })

        const text = response.content.find(
          (c) => c.type === "text"
        ) as any

        if (!text) {
          return yield* Effect.fail({
            _tag: "InvalidJSON" as const,
            message: "No text in response",
          })
        }

        return JSON.parse(text.text)
      })

    // Retry only on retryable errors
    const result = yield* callLLM().pipe(
      Effect.retry(
        schedule.pipe(
          Schedule.whileInput((error) =>
            isRetryable(error)
          )
        )
      ),
      Effect.catchTag("Timeout", (error) =>
        Effect.fail(error)
      ),
      Effect.catchTag("NetworkError", (error) =>
        Effect.fail(error)
      )
    )

    return result
  })

// 5. Full pipeline with retry and parse
const analyzeSafely = (prompt: string) =>
  Effect.gen(function* () {
    // Call with retry
    const raw = yield* callLLMWithRetry(prompt)

    // Parse with categorized errors
    const parseResult = yield* parseResponse(raw)

    if (parseResult._tag === "Success") {
      return parseResult.data
    }

    const error = parseResult.error

    if (isRetryable(error)) {
      console.warn(
        `Retryable error (${error._tag}), giving up after retries: ${error.message}`
      )
    } else {
      console.error(
        `Non-retryable error (${error._tag}): ${error.message}`
      )
    }

    return yield* Effect.fail(error)
  })

// 6. Usage
const result = Effect.runPromise(
  analyzeSafely("What is the capital of France?")
).catch((error) => {
  console.error("Final error:", error)
})
```

# Why This Works

| Concept | Explanation |
|---------|-------------|
| Error categorization | Distinguish temporary (network) from permanent (schema) failures |
| Exponential backoff | Start fast, slow down to avoid overwhelming system |
| Jitter | Random delay prevents thundering herd on retries |
| Schedule composition | Retry up to N times with time limits |
| `isRetryable` check | Only retry when it might help |

# When to Use

- Transient network failures
- Rate-limited LLM APIs
- Flaky model outputs that improve on retry
- Production systems needing resilience
- When you want to distinguish retry-worthy from permanent failures

# Related Patterns

- [Basic AI Response Parsing](./basic.md)
- [Handling Malformed AI Outputs](./error-recovery.md)
- [Parsing Partial/Incomplete Responses](./partial-responses.md)
- [Validating Streaming AI Responses](./streaming-validation.md)
