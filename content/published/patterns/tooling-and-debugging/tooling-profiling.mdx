---
title: Profile Effect Applications
id: tooling-profiling
skillLevel: advanced
applicationPatternId: tooling-and-debugging
summary: Measure and optimize performance of Effect applications.
tags:
  - tooling
  - profiling
  - performance
  - optimization
rule:
  description: >-
    Use Effect's timing features and Node.js profilers to find performance
    bottlenecks.
author: PaulJPhilp
related:
  - tooling-devtools
  - observability-custom-metrics
lessonOrder: 1
---

## Guideline

Profile Effect applications using built-in timing spans, metrics, and Node.js profiling tools.

---

## Rationale

Profiling helps you:

1. **Find bottlenecks** - What's slow?
2. **Optimize hot paths** - Focus effort where it matters
3. **Track regressions** - Catch slowdowns early
4. **Right-size resources** - Don't over-provision

---

## Good Example

### 1. Basic Timing with Spans

```typescript
import { Effect, Duration } from "effect"

// ============================================
// 1. Time individual operations
// ============================================

const timeOperation = <A, E, R>(
  name: string,
  effect: Effect.Effect<A, E, R>
) =>
  Effect.gen(function* () {
    const startTime = Date.now()

    const result = yield* effect

    const duration = Date.now() - startTime
    yield* Effect.log(`${name}: ${duration}ms`)

    return result
  })

// Usage
const program = Effect.gen(function* () {
  yield* timeOperation("database-query", queryDatabase())
  yield* timeOperation("api-call", callExternalApi())
  yield* timeOperation("processing", processData())
})

// ============================================
// 2. Use withLogSpan for nested timing
// ============================================

const timedProgram = Effect.gen(function* () {
  yield* Effect.log("Starting")

  yield* fetchUsers().pipe(Effect.withLogSpan("fetchUsers"))

  yield* processUsers().pipe(Effect.withLogSpan("processUsers"))

  yield* saveResults().pipe(Effect.withLogSpan("saveResults"))

  yield* Effect.log("Complete")
}).pipe(Effect.withLogSpan("total"))

// ============================================
// 3. Collect timing metrics
// ============================================

import { Metric } from "effect"

const operationDuration = Metric.histogram("operation_duration_ms", {
  description: "Operation duration in milliseconds",
  boundaries: [1, 5, 10, 25, 50, 100, 250, 500, 1000],
})

const profiledEffect = <A, E, R>(
  name: string,
  effect: Effect.Effect<A, E, R>
) =>
  Effect.gen(function* () {
    const startTime = Date.now()

    const result = yield* effect

    const duration = Date.now() - startTime
    yield* Metric.update(
      operationDuration.pipe(Metric.tagged("operation", name)),
      duration
    )

    return result
  })

// ============================================
// 4. Memory profiling
// ============================================

const logMemoryUsage = Effect.sync(() => {
  const usage = process.memoryUsage()
  return {
    heapUsed: Math.round(usage.heapUsed / 1024 / 1024),
    heapTotal: Math.round(usage.heapTotal / 1024 / 1024),
    external: Math.round(usage.external / 1024 / 1024),
    rss: Math.round(usage.rss / 1024 / 1024),
  }
})

const withMemoryLogging = <A, E, R>(effect: Effect.Effect<A, E, R>) =>
  Effect.gen(function* () {
    const before = yield* logMemoryUsage
    yield* Effect.log(`Memory before: ${JSON.stringify(before)}MB`)

    const result = yield* effect

    const after = yield* logMemoryUsage
    yield* Effect.log(`Memory after: ${JSON.stringify(after)}MB`)
    yield* Effect.log(`Memory delta: ${after.heapUsed - before.heapUsed}MB`)

    return result
  })

// ============================================
// 5. CPU profiling with Node.js inspector
// ============================================

const withCpuProfile = <A, E, R>(
  name: string,
  effect: Effect.Effect<A, E, R>
) =>
  Effect.gen(function* () {
    // Start CPU profiler (requires --inspect flag)
    const inspector = yield* Effect.try(() => {
      const { Session } = require("inspector")
      const session = new Session()
      session.connect()
      return session
    })

    yield* Effect.try(() => {
      inspector.post("Profiler.enable")
      inspector.post("Profiler.start")
    })

    const result = yield* effect

    // Stop and save profile
    yield* Effect.async<void>((resume) => {
      inspector.post("Profiler.stop", (err: Error, { profile }: any) => {
        if (err) {
          resume(Effect.fail(err))
        } else {
          const fs = require("fs")
          fs.writeFileSync(
            `${name}-${Date.now()}.cpuprofile`,
            JSON.stringify(profile)
          )
          resume(Effect.void)
        }
      })
    })

    return result
  })

// ============================================
// 6. Benchmark specific operations
// ============================================

const benchmark = <A, E, R>(
  name: string,
  effect: Effect.Effect<A, E, R>,
  iterations: number = 100
) =>
  Effect.gen(function* () {
    const times: number[] = []

    for (let i = 0; i < iterations; i++) {
      const start = performance.now()
      yield* effect
      times.push(performance.now() - start)
    }

    const sorted = times.sort((a, b) => a - b)
    const stats = {
      min: sorted[0],
      max: sorted[sorted.length - 1],
      median: sorted[Math.floor(sorted.length / 2)],
      p95: sorted[Math.floor(sorted.length * 0.95)],
      p99: sorted[Math.floor(sorted.length * 0.99)],
      mean: times.reduce((a, b) => a + b, 0) / times.length,
    }

    yield* Effect.log(`Benchmark "${name}" (${iterations} iterations):`)
    yield* Effect.log(`  Min:    ${stats.min.toFixed(2)}ms`)
    yield* Effect.log(`  Max:    ${stats.max.toFixed(2)}ms`)
    yield* Effect.log(`  Mean:   ${stats.mean.toFixed(2)}ms`)
    yield* Effect.log(`  Median: ${stats.median.toFixed(2)}ms`)
    yield* Effect.log(`  P95:    ${stats.p95.toFixed(2)}ms`)
    yield* Effect.log(`  P99:    ${stats.p99.toFixed(2)}ms`)

    return stats
  })

// ============================================
// 7. Profile concurrent operations
// ============================================

const profileConcurrency = Effect.gen(function* () {
  const items = Array.from({ length: 100 }, (_, i) => i)

  // Sequential
  yield* benchmark(
    "sequential",
    Effect.forEach(items, (i) => Effect.succeed(i * 2), { concurrency: 1 }),
    10
  )

  // Parallel unbounded
  yield* benchmark(
    "parallel-unbounded",
    Effect.forEach(items, (i) => Effect.succeed(i * 2), {
      concurrency: "unbounded",
    }),
    10
  )

  // Parallel limited
  yield* benchmark(
    "parallel-10",
    Effect.forEach(items, (i) => Effect.succeed(i * 2), { concurrency: 10 }),
    10
  )
})

// ============================================
// 8. Run profiling
// ============================================

const profilingSession = Effect.gen(function* () {
  yield* Effect.log("=== Profiling Session ===")

  yield* withMemoryLogging(
    benchmark("my-operation", someEffect, 50)
  )

  yield* profileConcurrency
})

Effect.runPromise(profilingSession)
```

## Profiling Output Example

```
Benchmark "my-operation" (50 iterations):
  Min:    1.23ms
  Max:    15.67ms
  Mean:   3.45ms
  Median: 2.89ms
  P95:    8.12ms
  P99:    12.34ms
```

## Profiling Tools

| Tool | Use For |
|------|---------|
| `withLogSpan` | Basic timing |
| `Metric.histogram` | Distribution tracking |
| `process.memoryUsage` | Memory profiling |
| Node.js Inspector | CPU profiling |
| `benchmark()` | Micro-benchmarks |

## Best Practices

1. **Profile in production-like env** - Dev differs from prod
2. **Warm up first** - JIT compilation affects early runs
3. **Use percentiles** - Mean hides outliers
4. **Profile before optimizing** - Don't guess
5. **Track over time** - Catch regressions

