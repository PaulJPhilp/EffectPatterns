import { Command } from "@effect/cli";
import { FileSystem } from "@effect/platform";
import { Path } from "@effect/platform/Path";
import { Option } from "effect";
import { ConfigService } from "../services/config-service/service.js";
import { MetricsService } from "../services/metrics-service/service.js";
import { OtelService } from "../services/otel-service/service.js";
export declare const generateCommand: Command.Command<"generate", import("../services/mdx-service/service.js").MdxService | FileSystem.FileSystem | Path | ConfigService | import("../services/prompt-template/service.js").TemplateService | import("@effect/ai-google/GoogleAiClient").GoogleAiClient | import("@effect/ai-openai/OpenAiClient").OpenAiClient | import("@effect/ai-anthropic/AnthropicClient").AnthropicClient | import("@effect/platform/HttpClient").HttpClient | MetricsService | OtelService, import("@effect/platform/Error").PlatformError | Error, {
    readonly file: Option.Option<string>;
    readonly provider: Option.Option<"google" | "openai" | "anthropic">;
    readonly model: Option.Option<string>;
    readonly output: Option.Option<string>;
    readonly outputFormat: Option.Option<"json" | "text">;
    readonly schemaPrompt: Option.Option<string>;
    readonly stdin: boolean;
    readonly noStream: boolean;
    readonly quiet: boolean;
    readonly json: boolean;
    readonly temperature: Option.Option<number>;
    readonly maxTokens: Option.Option<number>;
    readonly topP: Option.Option<number>;
    readonly seed: Option.Option<number>;
}>;
export declare const genAliasCommand: Command.Command<"gen", import("../services/mdx-service/service.js").MdxService | FileSystem.FileSystem | Path | ConfigService | import("../services/prompt-template/service.js").TemplateService | import("@effect/ai-google/GoogleAiClient").GoogleAiClient | import("@effect/ai-openai/OpenAiClient").OpenAiClient | import("@effect/ai-anthropic/AnthropicClient").AnthropicClient | import("@effect/platform/HttpClient").HttpClient | MetricsService | OtelService, import("@effect/platform/Error").PlatformError | Error, {
    readonly file: Option.Option<string>;
    readonly provider: Option.Option<"google" | "openai" | "anthropic">;
    readonly model: Option.Option<string>;
    readonly output: Option.Option<string>;
    readonly outputFormat: Option.Option<"json" | "text">;
    readonly schemaPrompt: Option.Option<string>;
    readonly stdin: boolean;
    readonly noStream: boolean;
    readonly quiet: boolean;
    readonly json: boolean;
    readonly temperature: Option.Option<number>;
    readonly maxTokens: Option.Option<number>;
    readonly topP: Option.Option<number>;
    readonly seed: Option.Option<number>;
}>;
export declare const processPromptLegacyCommand: Command.Command<"process-prompt", import("../services/mdx-service/service.js").MdxService | FileSystem.FileSystem | Path | ConfigService | import("../services/prompt-template/service.js").TemplateService | import("@effect/ai-google/GoogleAiClient").GoogleAiClient | import("@effect/ai-openai/OpenAiClient").OpenAiClient | import("@effect/ai-anthropic/AnthropicClient").AnthropicClient | import("@effect/platform/HttpClient").HttpClient | MetricsService | OtelService, import("@effect/platform/Error").PlatformError | Error, {
    readonly file: Option.Option<string>;
    readonly provider: Option.Option<"google" | "openai" | "anthropic">;
    readonly model: Option.Option<string>;
    readonly output: Option.Option<string>;
    readonly outputFormat: Option.Option<"json" | "text">;
    readonly schemaPrompt: Option.Option<string>;
    readonly stdin: boolean;
    readonly noStream: boolean;
    readonly quiet: boolean;
    readonly json: boolean;
    readonly temperature: Option.Option<number>;
    readonly maxTokens: Option.Option<number>;
    readonly topP: Option.Option<number>;
    readonly seed: Option.Option<number>;
}>;
export { genAliasCommand as effectPatternsGen, generateCommand as effectPatternsGenerate, processPromptLegacyCommand as effectPatternsProcessPromptLegacy, };
export declare const effectPatternsProcessPrompt: Command.Command<"process-prompt", import("../services/mdx-service/service.js").MdxService | FileSystem.FileSystem | Path | ConfigService | import("../services/prompt-template/service.js").TemplateService | import("@effect/ai-google/GoogleAiClient").GoogleAiClient | import("@effect/ai-openai/OpenAiClient").OpenAiClient | import("@effect/ai-anthropic/AnthropicClient").AnthropicClient | import("@effect/platform/HttpClient").HttpClient | MetricsService | OtelService, import("@effect/platform/Error").PlatformError | Error, {
    readonly file: Option.Option<string>;
    readonly provider: Option.Option<"google" | "openai" | "anthropic">;
    readonly model: Option.Option<string>;
    readonly output: Option.Option<string>;
    readonly outputFormat: Option.Option<"json" | "text">;
    readonly schemaPrompt: Option.Option<string>;
    readonly stdin: boolean;
    readonly noStream: boolean;
    readonly quiet: boolean;
    readonly json: boolean;
    readonly temperature: Option.Option<number>;
    readonly maxTokens: Option.Option<number>;
    readonly topP: Option.Option<number>;
    readonly seed: Option.Option<number>;
}>;
